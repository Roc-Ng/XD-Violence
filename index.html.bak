
<!-- saved from url=(0035)https://sdolivia.github.io/FineGym/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/analytics.js.下载"></script><script src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:16px;
		margin-left: auto;
		margin-right: auto;
		width: 800px;
	}
	
	h1 {
		font-weight:300;
	}
		
	h2 {
		font-weight:300;
		font-size: 22px;
		text-align: left;
	}

	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

	pre {
    text-align: left;
    white-space: pre;
	background-color: ghostwhite;
	border: 1px solid #CCCCCC;
	padding: 10px 20px;
	margin: 10px;
    tab-size:         4; /* Chrome 21+, Safari 6.1+, Opera 15+ */
    -moz-tab-size:    4; /* Firefox 4+ */
    -o-tab-size:      4; /* Opera 11.5 & 12.1 only */
  	}

</style>


  
		<title>XD-Violence</title>
		<meta property="og:image" content="">
		<meta property="og:title" content="Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision">
  </head>

  <body>
    <br>
          <center>
          	<span style="font-size:42px">Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision</span>
	  		  <table align="center" width="600px">
	  			  <tbody><tr>
	  	              <td align="center" width="100px">
	  					<center>
	  						<span style="font-size:24px"><a href="https://roc-ng.github.io/">Peng Wu</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align="center" width="100px">
	  					<center>
	  						<span style="font-size:24px"><a href="https://faculty.xidian.edu.cn/LJ22/zh_CN/lwcg/339624/list/index.htm">Jing Liu</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align="center" width="100px">
	  					<center>
	  						<span style="font-size:24px"><a href="https://roc-ng.github.io/XD-Violence/">Yujia Shi</a></span>
		  		  		</center>
		  		  	  </td>
					<td align="center" width="100px">
						<center>
							<span style="font-size:24px"><a href="https://roc-ng.github.io/XD-Violence/">Yujia Sun</a></span>
						</center>
					</td>
					</tr></tbody></table>

			  <table align="center" width="600px">
				  <tbody><tr>
					<td align="center" width="100px">
						<center>
							<span style="font-size:24px"><a href="https://roc-ng.github.io/XD-Violence/">Fangtao Shao</a></span>
						</center>
					</td>
					<td align="center" width="100px">
						<center>
							<span style="font-size:24px"><a href="https://roc-ng.github.io/XD-Violence/">Zhaoyang Wu</a></span>
						</center>
					</td>
					<td align="center" width="100px">
						<center>
							<span style="font-size:24px"><a href="https://roc-ng.github.io/XD-Violence/">Zhiwei Yang</a></span>
						</center>
					</td>
				</tr></tbody></table>
          		<!-- <span style="font-size:30px">ECCV 2016.</span> -->

			  <table align="center" width="600px">
				  <tbody><tr>
					  <td align="center" width="100px">
						<center>
							<span style="font-size:20px"><a href="https://en.xidian.edu.cn/">Xidian University</a></span>
						</center>
					  </td>
			  </tr></tbody></table>
			European Conference on Computer Vision (<a href="https://eccv2020.eu/" target="_blank">ECCV</a>) 2020, <font color="#e86e14">Poster Presentation</font>
          </center>

   		  <br><br>
		  <hr>

  		  <br>
  		  <table align="center" width="720px">
  			  <tbody><tr>
  	              <td width="400px">
  					<center>
  	                	<a href="./images/samples.png"><img class="rounded" src="./images/samples.png" width="800px"></a><br>
					</center>
  	              </td>
                </tr>
  	              <tr><td width="400px">
  					<center>
  	                	<span style="font-size:14px"><i>Sample videos from the XD-Violence dataset.</i>
					</span></center>
  	              </td>

  		  </tr></tbody></table>
      	  <br><br>
		  <hr>


  		  <center><h1>Abstract</h1></center><table align="center" width="720px">
				
		  </table>
		  <center>
			<span>
		 	Violence detection has been studied in computer vision for years. However, previous work are either superficial, e.g., classification of short-clips, and the single scenario, or undersupplied, e.g., the single modality, and hand-crafted features based multimodality. To address this problem, in this work we first release a large-scale and multi-scene dataset named XD-Violence with a total duration of 217 hours, containing 4754 untrimmed videos with audio signals and weak labels. Then we propose a neural network containing three parallel branches to capture different relations among video snippets and integrate features, where holistic branch captures long-range dependencies using similarity prior, localized branch captures local positional relation using proximity prior, and score branch dynamically captures the closeness of predicted score. Besides, our method also includes an approximator to meet the needs of online detection. Our method outperforms other state-of-the-art methods on our released dataset and other existing benchmark. Moreover, extensive experimental results also show the positive effect of multimodal input and modeling relationships.
		  	</span>
		  </center>
  		  <br><br>
		  <hr>

		  <center><h1>Demo video</h1></center><table align="center" width="720px">
			
			<tbody><tr>
				</tr></tbody></table><table align="center" width="720px">
					<tbody><tr>
						<td align="center" width="720px">
							<iframe width="600" height="320" src=".https://roc-ng.github.io/XD-Violence/" frameborder="0" allowfullscreen=""></iframe>
						</td>
					  </tr>
					<tr>
						<td align="center" width="720px">
						  <span style="font-size:14px">To Be Continued 
						</span>
						   </td>
					  </tr>
					 </tbody></table>
			  
		  
		   <br><br>
		  <hr>


		  <center><h1>Sub-action examples</h1></center><center>
				<span>
					We present several examples of fine-grained sub-action instances.
					Each group belongs to three element categories within a same event (BB, FX, UB, and VT).
					It can be seen such fine-grained instances contain subtle and challenging differences.
					(Hover on the GIF for a 0.25x slowdown)</span>
				<br>
				</center><table align="center" width="720px">
			
			<tbody><tr>
				
				<td width="360px">
					<center>
						<span style="font-size:22px"><a>Balance Beam (BB)</a></span><br>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_bb_01_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_bb_01_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_bb_01_normal.gif" width="100px"></a>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_bb_02_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_bb_02_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_bb_02_normal.gif" width="100px"></a>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_bb_03_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_bb_03_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_bb_03_normal.gif" width="100px"></a>
					</center>
				</td>
				<td width="360px">
					<center>
						<span style="font-size:22px"><a>Floor Exercise (FX)</a></span><br>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_fx_01_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_fx_01_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_fx_01_normal.gif" width="100px"></a>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_fx_02_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_fx_02_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_fx_02_normal.gif" width="100px"></a>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_fx_03_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_fx_03_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_fx_03_normal.gif" width="100px"></a>
					</center>
				</td>
			</tr>
			<tr>
				<td width="360px">
					<center>
						<span style="font-size:22px"><a>Uneven Bar (UB)</a></span><br>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_ub_01_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_ub_01_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_ub_01_normal.gif" width="100px"></a>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_ub_02_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_ub_02_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_ub_02_normal.gif" width="100px"></a>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_ub_03_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_ub_03_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_ub_03_normal.gif" width="100px"></a>
					</center>
				</td>
				<td width="360px">
					<center>
						<span style="font-size:22px"><a>Vault (VT)</a></span><br>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_vt_01_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_vt_01_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_vt_01_normal.gif" width="100px"></a>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_vt_02_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_vt_02_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_vt_02_normal.gif" width="100px"></a>
						<a><img onmouseover="this.src=&#39;./resources/examples/example_vt_03_slow.gif&#39;;" onmouseout="this.src=&#39;./resources/examples/example_vt_03_normal.gif&#39;;" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/example_vt_03_normal.gif" width="100px"></a>
					</center>
				</td>
			</tr>
		  </tbody></table>

		  <br><br>
		  <hr>

		  <center><h1>Dataset Statistics</h1></center><table align="center" width="720px">
			
			</table><center> </center><table>
			
			<tbody><tr>
				  <td width="400px">
				  <center>
					  <a><img class="rounded" src="./images/dataset1.png" width="500px"></a><br>
				</center>
				</td>
			</tr>
			<tr>
				<td align="center" width="720px">
				  <span style="font-size:14px"><i>
					Dataset Statistics. (a) Distribution of the number of videos belonging to each category according to multi-label. (b) Distribution of the number of videos belonging to each category according to the first label.</i>
				</span>
				</td>
			</tr>
			</tbody></table>

			<br>

			<center><h2></h2></center><table>
			
			<tbody><tr>
				  <td width="400px">
				  <center>
					  <a><img class="rounded" src="./images/dataset2.png" width="500px"></a><br>
				</center>
				</td>
			</tr>
			<tr>
				<td align="center" width="720px">
				  <span style="font-size:14px"><i>
					Dataset Statistics. (a) Distribution of videos according to length (minutes). (b) Distribution of violent videos according to percentage of violence (in each video) in test set.</i>
				</span>
				</td>
			</tr>
			</tbody></table>

			<br>

			<center><h2></h2></center>
				<br><table>
				
				<tbody><tr>
					  <td width="400px">
					  <center>
						  <a><img class="rounded" src="./images/dataset3.png" width="500px"></a><br>
					</center>
					</td>
				</tr>
				<tr>
					<td align="center" width="720px">
					  <span style="font-size:14px"><i>
						Comparisons of different violence datasets. ∗ means quite a few videos are silent or only contain background music.</i>
					</span>
					</td>
				</tr>
				</tbody></table>

			<br>

			<center><h2>Traits </h2></center>
				1) large scale, which is beneficial for training generalizable methods for violence detection; <br>
                2) diversity of scenarios, so that violence detection methods actively respond to complicated and diverse environments and are more robust; <br>
				3) containing audio signals, making algorithms leverage multimodal information and more confidence; <br>
				4) multi labels, We assign multi violent labels (1 ≤ #labels ≤ 3) to each violent video owing to the co-occurrence of violent events. The order of labels of each video is based on the importance of different violent events occurring in the video. 
				
			<br>
			

		  <center><h1>Download</h1></center><table id="download" align="center" width="720px">
			
			<tbody><tr>
				<td width="300px">
					<center>
						<span style="font-size:24px">V1.0 Videos</span><br>
						<br>
						<img class="rounded" onmouseover="this.src=&#39;./resources/images/dataset_icon.jpg&#39;;" onmouseout="this.src=&#39;./resources/images/dataset_icon.jpg&#39;;" src="./images/data_icon.png" height="150px"><br><br>
						<span style="font-size:16px"><a href="链接：https://pan.baidu.com/s/1vDmHyCOos23oj612JNHexQ">Training Videos [keyword:1ltx]</a></span><br>
						<span style="font-size:16px"><a href="https://pan.baidu.com/s/1YSDDX2hjzgujVJKVP2M-aA">Test Videos [keyword:exye]</a></span><br>
						<span style="font-size:16px"><a href="https://pan.baidu.com/s/1m74Uwuy6N8P3ceYTCS956w">Test Annotations [Keyword:3wd0]</a></span><br>
						<span style="font-size:16px"><a href="https://pan.baidu.com/s/1m74Uwuy6N8P3ceYTCS956w">ReadMe</a></span><br>
					<span style="font-size:16px"></span>
					</center>
				</td>
			</tr></tbody></table>
				


		 <center><h1>Paper</h1></center><table align="center" width="720px">
			
			   <tbody><tr>
				 <td align="center"><a href="https://sdolivia.github.io/FineGym/"><img class="layered-paper-big" style="height:160px" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/paper_pdf_thumb.png"></a></td>
				 <td><span style="font-size:14pt">Peng Wu et al.<br>
				 Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision<br>
				 In ECCV, 2020.<br>
				 (<a href="https://arxiv.org/abs/2004.06704">arXiv</a>)
				 <span style="font-size:4pt"><a href="https://sdolivia.github.io/FineGym/"><br></a>
				 </span>
				 </span></td>
				 <td align="center"><a href="https://sdolivia.github.io/FineGym/"><img class="layered-paper-big" style="height:160px" src="./FineGym_ A Hierarchical Video Dataset for Fine-grained Action Understanding_files/supp_pdf_thumb.png"></a></td>
				 <td><span style="font-size:14pt">
				 (<a href="https://sdolivia.github.io/FineGym/resources/supp.pdf">Supplementary materials</a>)
				 <span style="font-size:4pt"><a href="https://sdolivia.github.io/FineGym/"><br></a>
				 </span>
				 </span></td>
			 </tr>
		   </tbody></table>
		 
		 <br><br>
		 <hr>

		  <center><h1>Cite</h1></center><div class="disclaimerbox">
			<!-- <center><h2>How to interpret the results</h2></center> -->

		   <span>
				<!-- <center><span style="font-size:28px"><b>Cite</b></span></center> -->
				<pre style="font-family:Courier; font-size:14px">@inproceedings{Wu2020not,
title={Not only Look, but also Listen: Learning Multimodal Violence Detection under 
Weak Supervision},
author={Wu, Peng and Liu, jing and Shi, Yujia and Sun, Yujia and Shao, Fangtao 
and Wu, Zhaoyang and Yang, Zhiwei},
booktitle={European Conference on Computer Vision (ECCV)},
year={2020}
}
				</pre>
		  </span></div><table align="center" width="1020px">
			
		  
  		  </table>

			<br><br>
			<hr>
  
		  	
  		  <table align="center" width="720px">
  			  <tbody><tr>
  	              <td width="400px">
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
				We sincerely thank <b>Wang Chao</b>, <b>Ying Chaolong</b>, and <b>Yuan Kaixin</b> for their excellent annotation work.

				This work was supported in part by the Key Project of Science and Technology Innovation 2030 supported by the Ministry of Science and Technology of China under Grant 2018AAA0101302 and in part by the General Program of National Natural Science Foundation of China (NSFC) under Grant 61773300.

				The template of this webpage is borrowed from <a href="https://richzhang.github.io/colorization/">Richard Zhang</a><a>.
			</a></left><a>
		</a></td>
			 </tr>
		</tbody></table>

		<br><br>
		<hr>

		<table align="center" width="720px">
			<tbody><tr>
				<td width="400px">
				  <left>
			<center><h1>Contact</h1></center>
			For further questions and suggestions, please contact Peng Wu (<a href="xdwupeng@gmail.com">xdwupeng@gmail.com</a>).
			
			
		</left>
	</td>
		 </tr>
	</tbody></table>

		<br><br>

<script>
	
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75863369-1', 'auto');
  ga('send', 'pageview');

</script>
              


 
</body></html>